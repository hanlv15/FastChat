启动fastchat

python3 -m fastchat.serve.controller --port 21005
python3 -m fastchat.serve.controller --port 21006
python3 -m fastchat.serve.controller --port 21007

# 多模型
CUDA_VISIBLE_DEVICES=1,2 python -m fastchat.serve.multi_model_worker \
    --model-path /home/css/models/Orca-2-7b \
    --model-names Orca-2-7b \
    --model-path /home/css/models/openchat_3.5 \
    --model-names openchat_3.5 \
    --num-gpus 2 --max-gpu-memory 22GiB

# worker 0
CUDA_VISIBLE_DEVICES=0 python3 -m fastchat.serve.model_worker \
    --model-path /home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/output/openchat_3.5/eval_times=0/with_solar_info/brave/data1/lr=6e-5/lora_rank=8/split_type=8:2-train_ratio=1.0-20240118-09:36:28/checkpoint-609 \
    --controller http://localhost:21005 \
    --port 31000 \
    --worker http://localhost:31000


# worker 1
CUDA_VISIBLE_DEVICES=1 python3 -m fastchat.serve.model_worker \
    --model-path /home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/output/openchat_3.5/eval_times=0/with_solar_info/brave/data1/lr=1.2e-4/lora_rank=16/split_type=8:2-train_ratio=1.0-20240117-20:14:57/checkpoint-609 \
    --controller http://localhost:21005 \
    --port 31001 \
    --worker http://localhost:31001

CUDA_VISIBLE_DEVICES=1 python3 -m fastchat.serve.model_worker \
    --model-path /home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/output/openchat_3.5/eval_times=0/with_solar_info/brave/data1/lr=2e-4/lora_rank=8/split_type=8:2-train_ratio=1.0-20240117-18:11:17/checkpoint-609 \
    --model-names checkpoint-609-1 \
    --controller http://localhost:21005 \
    --port 31001 \
    --worker http://localhost:31001


CUDA_VISIBLE_DEVICES=1 python3 -m fastchat.serve.model_worker \
    --model-path /home/css/models/SOLAR-10.7B-Instruct-v1.0 \
    --controller http://localhost:21006 \
    --port 31001 \
    --worker http://localhost:31001


# worker 2
CUDA_VISIBLE_DEVICES=2 python3 -m fastchat.serve.model_worker \
    --model-path /home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/output/openchat_3.5/eval_times=0/with_solar_info/data4.1/lr=9e-5/split_type=8:2-train_ratio=1.0-20240111-05:58:10/checkpoint-609-2 \
    --controller http://localhost:21005 \
    --port 31002 \
    --worker http://localhost:31002

CUDA_VISIBLE_DEVICES=2 python3 -m fastchat.serve.model_worker \
    --model-path /home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/output/openchat_3.5/eval_times=0/with_solar_info/brave/data1/lr=1.8e-4/lora_rank=8/split_type=8:2-train_ratio=1.0-20240117-14:04:19/checkpoint-609 \
    --model-names checkpoint-609-2 \
    --controller http://localhost:21005 \
    --port 31002 \
    --worker http://localhost:31002

CUDA_VISIBLE_DEVICES=2 python3 -m fastchat.serve.model_worker \
    --model-path /home/css/models/SOLAR-10.7B-Instruct-v1.0 \
    --controller http://localhost:21007 \
    --port 31002 \
    --worker http://localhost:31002

# OpenAI API
python -m fastchat.serve.openai_api_server --controller http://localhost:21005 --host localhost --port 8001
python -m fastchat.serve.openai_api_server --controller http://localhost:21006 --host localhost --port 8002
python -m fastchat.serve.openai_api_server --controller http://localhost:21007 --host localhost --port 8003

# 调试
CUDA_VISIBLE_DEVICES=0 python3 -m fastchat.serve.cli \
    --model-path /home/css/models/NeuralBeagle14-7B \
    --debug

# UI
python3 -m fastchat.serve.gradio_web_server

# swift UI
CUDA_VISIBLE_DEVICES=1 swift app-ui --ckpt_dir /home/hanlv/workspace/code/research/infodemic/LLM/swift/examples/pytorch/llm/output/openchat_3.5/without_info/20231218-07:43:24-split_type=8:2-train_ratio=1.0/checkpoint-609

CUDA_VISIBLE_DEVICES=0 python3 -m fastchat.serve.model_worker \
    --model-path /home/css/models/Orca-2-7b \
    --controller http://localhost:21001 \
    --port 31000 \
    --worker http://localhost:31000

